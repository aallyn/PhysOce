library_check<- function(libraries) {
  ## Details
  # This function will check for and then either load or install any libraries needed to run subsequent functions
  
  # Args:
  # libraries = Vector of required library names
  
  # Returns: NA, just downloads/loads libraries into current work space.
  
  ## Start function
  lapply(libraries, FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE)
      library(x, character.only = TRUE)
    }
  })
  ## End function
}

fix_raster<- function(x, lons.use, lats.use, x.min.use, x.max.use, y.min.use, y.max.use) {
  ## Details
  # This function helps convert an array (x, y, z) into raster layers with the correct dimensions and orientation.
  
  # Args:
  # x = A matrix. As currently implemented, x is an individiaul time slice from an x, y, z array.
  # lons.use = Longitudes, extracted using ncvar_get
  # lats.use = Latitudes, extracted using ncvar_get
  # x.min.use = Bounding box x minimum
  # x.max.use = Bounding box x maximum
  # y.min.use = Bounding box x minimum
  # y.max.use = Bounding box x maximum
  
  # Returns: Correctly oriented raster layer
  
  ## Start function
  r.temp<- t(x)[ncol(x):1,]
  rast.out<- raster(r.temp, xmn = lons.use[x.min.use], xmx = lons.use[x.max.use], ymn = lats.use[y.min.use], ymx = lats.use[y.max.use])
  return(rast.out)
  
  ## End function
}

convert_kelvin_to_celsius<- function(temp) {
  ## Details
  # A simple function to convert kelvin temperaturs to degrees Celsius (needed for CMIP5) 
  
  # Args:
  # temp = Temperatures in Kelvin
  
  # Returns: Temperatures in degrees Celsius
  
  ## Start function
  celsius<- temp - 273.15
  return(celsius)
  
  ## End function
}

make_climate_threddsURL<- function(project, model.short, experiment, frequency, model.realm1, model.realm2, ensemble, version, variable){
  ## Details
  # This function will build THREDDS URLs based on supplied parameters, which are most easily brought into R as a model parameter input file. 
  
  # Args:
  # project = CMIP project, one of either "cmip5" or "cmip6"
  # model.short = Organization/Institution model name (e.g., GFDL-ESM2G)
  # experiment = Climate scenario experiment, without decimals (e.g., "rcp85", "rcp60")
  # frequency = Time step of projections (e.g., "mon")
  # model.realm1 = Modeling realm (e.g., "ocean")
  # model.realm2 = Modeling realm1 and frequency? (e.g., "Omon")
  # ensemble = Ensemble ID for specific model.short/experiment (e.g., r1i1p1 for CMIP5)
  # version = Version ID (guessing this is generated by model developers) (e.g., "v20110601")
  # variable = Shorthand for variable of interest (e.g., "tos" for sea surface temperature)
  
  # Returns: A vector of threddsURLS
  
  ## Start function
  # Libraries
  library_check(c("lubridate"))
  
  # For debugging
  if(FALSE){
    project = "cmip5"
    project = "cmip6"
    model.short = "GFDL-ESM2G"
    model.short = "GFDL-CM4"
    experiment = "rcp85"
    experiment = "piControl"
    frequency = "mon"
    model.realm1 = "ocean"
    model.realm2 = "Omon"
    ensemble = "r1i1p1"
    ensemble = "r1i1p1f1"
    version = "v20110601"
    version = "v20190201"
    variable = "tos"
  }
  
  # Each of the projects are set up a bit differently -- so going to make two different pieces, one URL creation for cmip5 and the other for cmip6
  if(project == "cmip5"){
    thredds.base<- "http://esgdata.gfdl.noaa.gov/thredds/dodsC/gfdl_dataroot/NOAA-GFDL/"
    
    # Getting list of datasets
    # Getting time period chunks of the different nc files
    date.starts<- as.Date(seq(ymd('2006-01-01'), ymd('2100-12-31'), by='5 years'))
    starts<- gsub("-", "", format(date.starts, "%Y-%m"))
    ends<- gsub("-", "", format(as.Date(seq(ymd('2010-12-01'), ymd('2100-12-31'),by='5 years')), "%Y-%m"))
    dates<- paste(paste(starts, ends, sep = "-"), ".nc", sep = "")
    
    # Creating list of nc files
    thredds.part1<- paste(model.short, experiment, frequency, model.realm1, model.realm2, ensemble, version, variable, sep = "/")
    thredds.part2<- paste("/", paste(variable, model.realm2, model.short, experiment, ensemble, dates, sep = "_"), sep = "")
    thredds.urls<- paste(thredds.base, thredds.part1, thredds.part2, sep = "")
    
    return(thredds.urls)
  }
  
  # Now, cmip6 URL
  if(project == "cmip6"){
    thredds.base<- "http://esgdata.gfdl.noaa.gov/thredds/dodsC/gfdl_dataroot4/CMIP/NOAA-GFDL/"
    
    # Getting list of datasets
    # Getting time period chunks of the different nc files
    duration<- ymd('0170-12-31') - ymd('0151-01-01')
    date.starts<- as.Date(seq(ymd('0151-01-01'), ymd('0631-12-31'), by = duration+1))
    starts<- gsub("-", "", format(date.starts, "%Y-%m"))
    ends<- gsub("-", "", format(as.Date(seq(ymd('0170-12-31'), ymd('0650-12-31'), by = duration)), "%Y-%m"))
    dates<- paste(paste(starts, ends, sep = "-"), ".nc", sep = "")
    
    # Creating list of nc files
    thredds.part1<- paste(model.short, experiment, ensemble, model.realm2, variable, "gn", version, sep = "/")
    thredds.part2<- paste("/", paste(variable, model.realm2, model.short, experiment, ensemble, "gn", dates, sep = "_"), sep = "")
    thredds.urls<- paste(thredds.base, thredds.part1, thredds.part2, sep = "")
    
    return(thredds.urls)
  }
  
  ## End function
}

clim_data_extract<- function(thredds.urls, box, project, out.path){
  ## Details
  # This function accesses climate projection data for URLs supplied in the thredds.urls character vector and crops full extent to a focal box of interest
  
  # Args:
  # thredds.urls = A vector of threddsURLS
  # box = Coordinates for focal box. Box should be specified as box = c(xmin, xmax, ymin, ymax) in decimal degrees (-180:180, -90:90).
  # project = CMIP project, one of either "cmip5" or "cmip6" to faciliate data collection and processing given differences in output between the two projects
  # out.path = If not NULL, a directory to save the resulting raster stack, which will overwrite any existing file with the same name.
  
  # Returns: A raster stack
  
  ## Start function
  # Libraries
  library_check(c("tidyverse", "raster", "ncdf4"))
  
  # For debugging
  if(FALSE){
    thredds.urls<- thredds.use$Thredds.URLS[[1]]
    thredds.urls<- thredds.urls
    box<- c(-77, -60, 35, 46)
    project<- "cmip5"
    out.path<- "./Output/"
  }
  
  # Looping over thredds.urls -- project dependent!
  if(project == "cmip5") {
    for(i in seq_along(thredds.urls)){
      
      # Connecting and extracting lat/lon/time variables from netcdf file
      my.nc<- nc_open(thredds.urls[i])
      lats<- ncvar_get(my.nc, var = "rlat")
      lons<- ncvar_get(my.nc, var = "rlon")
      times<- ncvar_get(my.nc, var = "time")
      
      # Make times a little bit easier to handle
      dates.full<- as.Date(times, origin = "2006-01-01")
      
      # Find indices and windows corresponding to spatial box of interest, which are then used in the "start" and "count" arguments to the ncvar_get call for the sst variable
      b.box<- c(box[1], box[2], box[3], box[4])
      
      x.window<- which(lons > b.box[1] & lons < b.box[2])
      x.min<- min(x.window)
      x.max<- max(x.window)
      x.count<- ifelse(x.max - x.min > 0, x.max-x.min, 1)
      
      y.window<- which(lats > b.box[3] & lats < b.box[4])
      y.min<- min(y.window)
      y.max<- max(y.window)
      y.count<- ifelse(y.max - y.min > 0, y.max - y.min, 1) 
      
      time.min<- which.min(dates.full)
      time.max<- which.max(dates.full)
      time.count<- ifelse(time.max - time.min > 0, (time.max - time.min)+1, 1)
      
      # Now we have the lon,lat,time indices and windows, but need to match up their order with how they are handled in the ncvar_get call 
      dim.order <- sapply(my.nc$var$tos$dim, function(x) x$name)
      
      # Set start and counts
      start.use<- c("rlon" = x.min, "rlat" = y.min, "time" = time.min)
      count.use<- c("rlon" = x.count, "rlat" = y.count, "time" = time.count)
      
      # Run ncvar_get, adjusting order of start and count as needed
      temp<- ncvar_get(my.nc, varid = "tos", start = start.use[dim.order], count = count.use[dim.order])
      
      # Moving from the array format of temp to a raster stack
      temp.list<- lapply(seq(dim(temp)[3]), function(x) fix_raster(temp[,,x], lons.use = lons, lats.use = lats, x.min.use = x.min, x.max.use = x.max, y.min.use = y.min, y.max.use = y.max))
      rast.temp<- raster::stack(temp.list)
      
      # Convert to Celsius for CMIP5 output
      rast.temp<- calc(rast.temp, fun = convert_kelvin_to_celsius)
      
      # Add names?
      names(rast.temp)<- dates.full
      
      if(i == 1) {
        stack.out<- rast.temp
      } else {
        stack.out<- stack(stack.out, rast.temp)
      }
      print(paste(thredds.urls[i], "is done", sep = " "))
    }
    # Set projection information
    proj4string(stack.out)<- CRS("+init=epsg:4326")
    
    # Save it?
    if(!is.null(out.path)){
      file.name.temp1<- gsub("http://esgdata.gfdl.noaa.gov/thredds/dodsC/gfdl_dataroot/NOAA-GFDL/", "", thredds.urls[1])
      file.name.temp2<- strsplit(file.name.temp1, "/")
      file.name<- paste(file.name.temp2[[1]][1:length(file.name.temp2[[1]])-1], collapse = ".")
      writeRaster(stack.out, filename = paste(out.path, project, file.name, ".grd", sep = ""), overwrite = TRUE)
    }
  }
  
  # Now, CMIP6
  if(project == "cmip6"){
    
    for(i in seq_along(thredds.urls)){
      
      # Connecting and extracting lat/lon/time variables from netcdf file
      my.nc<- nc_open(thredds.urls[i])
      lats<- ncvar_get(my.nc, var = "y")
      lons<- ncvar_get(my.nc, var = "x")
      times<- ncvar_get(my.nc, var = "time")
      
      # Make times a little bit easier to handle -- these seem weird...
      dates.full<- as.Date(times, origin = "1700-01-01")
      
      # Find indices and windows corresponding to spatial box of interest, which are then used in the "start" and "count" arguments to the ncvar_get call for the sst variable
      b.box<- c(box[1], box[2], box[3], box[4])
      
      x.window<- which(lons > b.box[1] & lons < b.box[2])
      x.min<- min(x.window)
      x.max<- max(x.window)
      x.count<- ifelse(x.max - x.min > 0, x.max-x.min, 1)
      
      y.window<- which(lats > b.box[3] & lats < b.box[4])
      y.min<- min(y.window)
      y.max<- max(y.window)
      y.count<- ifelse(y.max - y.min > 0, y.max - y.min, 1) 
      
      time.min<- which.min(dates.full)
      time.max<- which.max(dates.full)
      time.count<- ifelse(time.max - time.min > 0, (time.max - time.min)+1, 1)
      
      # Now we have the lon,lat,time indices and windows, but need to match up their order with how they are handled in the ncvar_get call 
      dim.order <- sapply(my.nc$var$tos$dim, function(x) x$name)
      
      # Set start and counts
      start.use<- c("x" = x.min, "y" = y.min, "time" = time.min)
      count.use<- c("x" = x.count, "y" = y.count, "time" = time.count)
      
      # Run ncvar_get, adjusting order of start and count as needed
      temp<- ncvar_get(my.nc, varid = "tos", start = start.use[dim.order], count = count.use[dim.order])
      
      # Moving from the array format of temp to a raster stack
      temp.list<- lapply(seq(dim(temp)[3]), function(x) fix_raster(temp[,,x], lons.use = lons, lats.use = lats, x.min.use = x.min, x.max.use = x.max, y.min.use = y.min, y.max.use = y.max))
      rast.temp<- raster::stack(temp.list)
      
      # Add names?
      names(rast.temp)<- dates.full
      
      if(i == 1) {
        stack.out<- rast.temp
      } else {
        stack.out<- stack(stack.out, rast.temp)
      }
      print(paste(thredds.urls[i], "is done", sep = " "))
    }
    
    # Set projection information
    proj4string(stack.out)<- CRS("+init=epsg:4326")
    
    # Save it
    if(!is.null(out.path)){
      file.name.temp1<- gsub("http://esgdata.gfdl.noaa.gov/thredds/dodsC/gfdl_dataroot4/CMIP/NOAA-GFDL/", "", thredds.urls[1])
      file.name.temp2<- strsplit(file.name.temp1, "/")
      file.name<- paste(file.name.temp2[[1]][1:length(file.name.temp2[[1]])-1], collapse = ".")
      writeRaster(stack.out, filename = paste(out.path, project, file.name, ".grd", sep = ""), overwrite = TRUE)
    }
  }
  
  # Return it 
  return(stack.out)
  
  ## End function
}

as.year <- function(x) as.numeric(floor(as.yearmon(x)))
as.mon <- function(x) as.numeric(floor(month(x)))

calc_climatology<- function(raster.ts, res.ts = c("daily", "monthly", "yearly"), res.clim = c("daily", "monthly", "yearly"), baseline = c("1982-01-01", "2011-01-01"), out.path, out.file){
  ## Details
  # This function calculateds a climatology at a given temporal resolution (defined by res.clim) for an input raster time series stack
  
  # Args:
  # raster.ts = Either a raster time series stack OR the file path to a raster time series stack
  # res.ts = Character string defining the temporal resolution of the input raster time series. Currently, one of "daily", "monthly", or "yearly"
  # res.clim = Character string defining the temporal resolution of the input raster time series. Currently, one of "daily", "monthly", or "yearly"
  # baseline = Baseline period to use for the climatology
  # out.path = Path where to save the climatology mean and sd raster time series results

  # Returns: Climatology (mean and sd) of the input raster time series in the desired temporal resolution as a raster stack, which is also saved to an output folder.
  
  ## Start function
  # Libraries
  if(FALSE){
    raster.ts = all.rast.ts$Raster.TS[[2]]
    res.ts = all.rast.ts$res.ts[[2]]
    res.clim = "monthly"
    baseline = list(c("1982-01-01", "2011-01-01"))[[1]]
    out.path = all.rast.ts$Path[[2]]
    out.file = all.rast.ts$File[[2]]
  }
  
  # Houskeeping -- reading in if raster.ts is a file path, removing Feb 29th, setting Z dimension
  if(class(raster.ts) == "character"){
    rast.ts<- raster::stack(raster.ts)
    ts.dates<- format(as.Date(gsub("[.]", "-", gsub("X", "", names(rast.ts)))))
    rast.ts<- setZ(rast.ts, ts.dates)
    
    # Remove Feb 29th
    feb29<- which(format(as.Date(getZ(rast.ts), "%m-%d")) == "02-29")
    if(!is_empty(feb29)){
      rast.ts<- rast.ts[[-feb29]]
    } else {
      rast.ts<- rast.ts
    }
  } else {
    rast.ts<- raster.ts
    ts.dates<- format(as.Date(gsub("[.]", "-", gsub("X", "", names(rast.ts)))))
    rast.ts<- setZ(rast.ts, ts.dates)
    
    # Remove Feb 29th
    feb29<- which(format(as.Date(getZ(rast.ts), "%m-%d")) == "02-29")
    if(!is_empty(feb29)){
      rast.ts<- rast.ts[[-feb29]]
    } else {
      rast.ts<- rast.ts
    }
  }
  
  # Checking temporal resolution of the input data (res.data) and output (res.clim)
  res.match<- res.ts == res.clim
  
  # If necessary, aggregate the input raster time series stack to the desired temporal resolution for the climatology
  if(!res.match){
    agg.func<- switch(res.clim,
                      "monthly" = as.yearmon,
                      "yearly" = as.year)
    rast.ts<- zApply(rast.ts, by = agg.func, fun = mean, na.rm = TRUE)
  }
  
  # Calculate the climatology: mean and standard deviation
  # Subset to baseline period
  dates.all<- getZ(rast.ts)
  dates.clim.ind<- which(dates.all >= as.yearmon(baseline[1]) & dates.all < as.yearmon(baseline[2]))
  rast.ts.sub<- rast.ts[[dates.clim.ind]]
  rast.ts.sub<- setZ(rast.ts.sub, dates.all[dates.clim.ind])

  # Climatology
  # Conversion piece for matching up raster time series dates with dates.clim
  clim.tr<- switch(res.clim,
                   "daily" = "%m-%d",
                   "monthly" = "%m",
                   "yearly" = "%y")
  # Dates
  dates.clim<- unique(format(as.Date(getZ(rast.ts.sub)), clim.tr))

  # Climatology mean and sd
  clim.mu<- stack(lapply(seq(length(dates.clim)), function(x) calc(rast.ts.sub[[which(format(as.Date(getZ(rast.ts.sub)), clim.tr) == dates.clim[x])]], fun = mean, na.rm = TRUE)))
  names(clim.mu)<- dates.clim
  clim.mu<- setZ(clim.mu, dates.clim)
  clim.sd<- stack(lapply(seq(length(dates.clim)), function(x) calc(rast.ts.sub[[which(format(as.Date(getZ(rast.ts.sub)), clim.tr) == dates.clim[x])]], fun = sd, na.rm = TRUE)))
  names(clim.sd)<- dates.clim
  clim.sd<- setZ(clim.sd, dates.clim)

  # Return and save it
  return(list(clim.mu, clim.sd))
  writeRaster(clim.mu, paste(out.path, "/ClimMu.", gsub("Full", "", out.file), sep = ""), overwrite = TRUE)
  writeRaster(clim.sd, paste(out.path, "/ClimSD.", gsub("Full", "", out.file), sep = ""), overwrite = TRUE)

  # End function
}

calc_anomaly<- function(raster.ts, raster.clim.mu, raster.clim.sd, anom.type = "Standardized", out.path, out.file) {
  ## Details
  # This function calculates anomalies for a given raster time series from a climatology.
  
  # Args:
  # raster.ts = Either a raster time series stack OR the file path to a raster time series stack
  # raster.clim.mu = Either raster time series climatology that we will use to calculate the anomalies OR the file path to the raster time series climatology
  # raster.clim.sd = Either raster time series climatology standard deviation that we will use to calculate the anomalies OR the file path to the raster time series climatology standard deviation. Needed for standardized anomalies
  # anom.type = Character string, either Standardized or Non-Standardized
  # out.path = Path where to save the raster stack anomaly results
  
  # Returns: Raster stack of anomalies of the input raster time series, which is also saved to an output folder.
  
  ## Start function
  # Install libraries
  library_check(c("tidyverse", "sf", "raster", "rts"))
  
  # Set arguments for debugging -- this will NOT run when you call the function. Though, you can run each line inside the {} and then you will have everything you need to walk through the rest of the function.
  if(FALSE){
    raster.ts<- all.rast.ts$Raster.TS[[2]]
    raster.clim.mu = all.rast.ts$Clim.Mu[[2]]
    raster.clim.sd = all.rast.ts$Clim.SD[[2]]
    anom.type<- "Standardized"
  }
  
  # Reading in original raster data
  rast.ts<- raster::stack(raster.ts)
  rast.ts<- setZ(rast.ts, as.Date(gsub("[.]", "-", gsub("X", "", names(rast.ts)))))
  rast.clim.mu<- raster.clim.mu
  rast.clim.sd<- raster.clim.sd
  
  # Calculating the anomalies
  rts.anoms<- switch(anom.type, 
                       "Standardized" = stack(lapply(seq(1:nlayers(rast.ts)), function(x) (rast.ts[[x]] - rast.clim.mu[[match(format(getZ(rast.ts)[x], "%m"), gsub("X", "", names(rast.clim.mu)))]])/rast.clim.sd[[match(format(getZ(rast.ts)[x], "%m"), gsub("X", "", names(rast.clim.sd)))]])),
                       "Non-standardized" = stack(lapply(seq(1:nlayers(rast.ts)), function(x) (rast.ts[[x]] - rast.clim.mu[[match(format(getZ(rast.ts)[x], "%m"), gsub("X", "", names(rast.clim.mu)))]]))))
  names(rts.anoms)<- getZ(rast.ts)
  rts.anoms<- setZ(rts.anoms, getZ(rast.ts))
  
  # Write it out and save it
  writeRaster(rts.anoms, paste(out.path, "/ClimAnom.", gsub("Full", "", out.file), sep = ""), overwrite = TRUE)
  return(rts.anoms)
}

calc_proj_sst<- function(raster.anom, raster.clim, out.path, out.file){
  ## Details
  # This function calculates biased corrected sea surface temperature projections by appling raster anomalies from climate models to the observed OISST climatology
  
  # Args:
  # raster.anom = Raster stack anomalies from climate models
  # raster.clim = Raster stack of observed OISST temperatures
  # out.path = Path where to save the biased corrected sea surface temperature projections
  
  # Returns: Raster stack of biased corrected sea surface projections, which is also saved to an output folder.
  
  ## Start function
  # Install libraries
  library_check(c("tidyverse", "sf", "raster", "rts"))
  
  # Set arguments for debugging -- this will NOT run when you call the function. Though, you can run each line inside the {} and then you will have everything you need to walk through the rest of the function.
  if(FALSE){
    raster.anom = clim.rast.ts$Clim.Anom[[1]]
    raster.clim = all.rast.ts$Clim.Mu[[1]]
    out.path = clim.rast.ts$Path[[1]]
  }
  
  raster.clim.coarse<- resample(raster.clim, raster.anom, method = "bilinear")
  
  raster.proj.out<- stack(lapply(seq(1:nlayers(raster.anom)), function(x) (raster.anom[[x]] + raster.clim.coarse[[match(format(getZ(raster.anom)[x], "%m"), gsub("X", "", names(raster.clim.coarse)))]])))
  names(raster.proj.out)<- getZ(raster.anom)
  raster.proj.out<- setZ(raster.proj.out, getZ(raster.anom))
  
  # Write it out and save it
  writeRaster(raster.proj.out, paste(out.path, "/ProjSST.", gsub("Full", "", out.file), sep = ""), overwrite = TRUE)
  return(raster.proj.out)
}
  

# Extra stuff
if(FALSE){
  # Now, need to apply anomalies to the climatology...
  
  # Extracting temperatures for different regions, saving files and plotting time series
  for(i in seq_along(regions)){
    mask.use<- switch(regions[i],
                      "NELME" = st_read(paste(res.data.path, "Shapefiles/NELME_Regions/NELME_sf.shp", sep = "")),
                      "GoM" = st_read(paste(res.data.path, "Shapefiles/NELME_Regions/GoM_sf.shp", sep = "")),
                      "SNE-MAB" = st_read(paste(res.data.path, "Shapefiles/NELME_Regions/SNEandMAB_sf.shp", sep = "")))
    
    # Need to get climatology from the OISST data 
    # Mask
    #oisst.m<- mask(oisst.rts, mask.use)
    oisst.m<- oisst.rts
    
    # Baseline
    oisst.m.base<- oisst.m[[which(getZ(oisst.m) >= baseline[1] & getZ(oisst.m) <= baseline[2])]]
    oisst.m.base<- setZ(oisst.m.base, seq.Date(from = as.Date(baseline[1]), to = as.Date(baseline[2]), by = "day"))
    
    dates.unique<- unique(format(getZ(oisst.m), "%m-%d"))
    daily.means<- stack(lapply(seq(length(dates.unique)), function(x) calc(oisst.m.base[[which(format(getZ(oisst.m.base), "%m-%d") == dates.unique[x])]], fun = mean)))
    names(daily.means)<- dates.unique
    daily.sd<- stack(lapply(seq(length(dates.unique)), function(x) calc(oisst.m.base[[which(format(getZ(oisst.m.base), "%m-%d") == dates.unique[x])]], fun = sd)))
    names(daily.sd)<- dates.unique
    
    # Daily temps for KM
    daily.temps<- do.call("cbind", lapply(seq(1:nlayers(oisst.m)), function(x) as.data.frame(oisst.m[[x]], xy = TRUE)))
    daily.temps2<- daily.temps %>%
      subset(., select=which(!duplicated(names(.)))) %>%
      gather(., Year, SST, -x, -y) 
    
    daily.temps2$Year<- gsub("[.]", "-", gsub("X", "", daily.temps2$Year))
    daily.dat<- daily.temps2
    names(daily.dat)[3]<- "Date"
    daily.dat$Date<- as.Date(daily.dat$Date)
    daily.dat<- daily.dat %>%
      drop_na(SST)
    
    # Daily data
    write_csv(daily.dat, file = paste(out.dir, regions[i], ".SSTDailyDegF.csv", sep = ""))
    
    # Baseline data
    clim.temps<- do.call("cbind", lapply(seq(1:nlayers(daily.means)), function(x) as.data.frame(daily.means[[x]], xy = TRUE)))
    clim.temps2<- clim.temps %>%
      subset(., select=which(!duplicated(names(.)))) %>%
      gather(., Day, SST, -x, -y) 
    
    clim.temps2$Day<- paste("1944", gsub("[.]", "-", gsub("X", "", clim.temps2$Day)), sep = "-")
    clim.dat<- clim.temps2
    names(clim.dat)[3]<- "Date"
    clim.dat$Date<- as.Date(clim.dat$Date)
    clim.dat<- clim.dat %>%
      drop_na(SST) %>%
      group_by(Date) %>%
      summarize(., Mean.SST = mean(SST))
    
    # Clim data
    write.csv(clim.dat, file = paste("~/Desktop/", sub.regions[i], ".SSTDailyClimatologyDegF.csv", sep = ""))
    
    # Alright, now substract each daily OISST from the daily climatology to get the anomaly
    anom.type<- "Non.standardized"
    daily.anoms<- switch(anom.type, 
                         Standardized = stack(lapply(seq(1:nlayers(oisst.m)), function(x) (oisst.m[[x]] - daily.means[[match(format(getZ(oisst.m)[x], "%m-%d"), gsub("[.]", "-", gsub("X", "", names(daily.means))))]])/daily.sd[[match(format(getZ(oisst.m)[x], "%m-%d"), gsub("[.]", "-", gsub("X", "", names(daily.sd))))]])),
                         Non.standardized = stack(lapply(seq(1:nlayers(oisst.m)), function(x) (oisst.m[[x]] - daily.means[[match(format(getZ(oisst.m)[x], "%m-%d"), gsub("[.]", "-", gsub("X", "", names(daily.means))))]]))))
    names(daily.anoms)<- getZ(oisst.m)
    
    # Save it
    writeRaster(daily.anoms, filename = paste("~/Desktop/", sub.regions[i], ".grd", sep = ""), overwrite = TRUE)
    
    # Getting the anomalies
    ts.wide.daily<- do.call("cbind", lapply(seq(1:nlayers(daily.anoms)), function(x) as.data.frame(daily.anoms[[x]], xy = TRUE)))
    ts.df.daily<- ts.wide.daily %>%
      subset(., select=which(!duplicated(names(.)))) %>%
      gather(., Year, SST, -x, -y) 
    names(ts.df.daily)[3]<- "Date"
    ts.df.daily$Date<- gsub("X", "", gsub("[.]", "-", ts.df.daily$Date))
    ts.df.daily<- ts.df.daily %>%
      separate(., Date, c("YYYY", "MM", "DD")) %>%
      group_by(., YYYY, MM, DD) %>%
      summarize_at(., "SST", mean, na.rm = T)
    
    # Save em
    write.csv(ts.df.daily, paste("~/Desktop/", sub.regions[i], "Anomalies.csv", sep = ""))
    
    # Keep going for individual region...
    ts.df.dailymu<- ts.df.daily %>%
      mutate(., "Plot.Date" = as.Date(paste(YYYY, MM, DD, sep = "-"))) %>%
      data.frame
    
    # Smooth daily values
    # Creat zoo series
    zoo.dates<- as.Date(ts.df.dailymu$Plot.Date)
    zoo.vals<- zoo(ts.df.dailymu$SST, zoo.dates)
    zoo.ts<- as.ts(zoo.vals)
    ts.df.dailymu$smoothed<- as.numeric(ma(zoo.vals, order = 15, centre = FALSE))
    
    ts.df.monthlymu<- ts.df.dailymu %>%
      group_by(YYYY, MM) %>%
      dplyr::summarize(., Mean.SST = mean(SST, na.rm =T)) %>%
      mutate(., Plot.Date = as.Date(paste(YYYY, MM, "15", sep = "-"))) %>%
      data.frame
    
    ts.df.yearlymu<- ts.df.dailymu %>%
      group_by(YYYY) %>%
      dplyr::summarize(., Mean.SST = mean(SST, na.rm = T)) %>%
      mutate(., Plot.Date = as.Date(paste(YYYY, "06", "15", sep = "-"))) %>%
      filter(., YYYY != format(Sys.time(), "%Y")) %>%
      data.frame()
    
    ts.df.yearlymu$Year.Model<- as.integer(ts.df.yearlymu$YYYY) - 1982
    
    # Plots
    d15<- TRUE
    if(d15 == TRUE){
      # Full trend line
      sst.anom.lm.full<- lm(Mean.SST ~ Year.Model, data = ts.df.yearlymu)
      summary(sst.anom.lm.full)
      adj.r2.full<- paste("Adj R2 = ", round(summary(sst.anom.lm.full)$adj.r.squared, 3), sep = "")
      
      # Fitted model formula
      my.formula.full<- paste("Mean.SST = ", signif(round(sst.anom.lm.full$coef[[1]], 3), 5), " + ", signif(round(sst.anom.lm.full$coef[[2]], 3), 5), "*Year", sep = "")
      base.ts<- ggplot(data = subset(ts.df.dailymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2017-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = smoothed)) + 
        geom_line(col = "#d9d9d9", lwd = 0.15) +
        geom_point(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2017-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), col = "black") +
        geom_line(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2017-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), col = "black", lwd = 0.25) +
        geom_smooth(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2017-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), method = "lm", formula = y ~ x, col = "#969696", size = 0.75, se = FALSE) +
        ylim(c(-3, 4)) +
        ylab("SST Anomaly (1982-2011 baseline)") + 
        xlab("Year") +
        theme_bw() +
        theme(axis.text=element_text(size=14),
              axis.title=element_text(size=16, face="bold"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank()) +
        geom_text(aes(x = as.Date("1987-06-15"), y = -2.5, label = my.formula.full), col = "#969696") +
        geom_text(aes(x = as.Date("1997-06-15"), y = -2.5, label = adj.r2.full), col = "#969696") 
      ggsave("~/Desktop/KM_sstanomaly_BaselineOnly.jpg", width = 8, height = 6, units = "in")
      
      # 2008-2017 trend line
      sst.anom.lm.plot2<- lm(Mean.SST ~ Year.Model, data = subset(ts.df.yearlymu, YYYY >= 2008 & YYYY <= 2017))
      summary(sst.anom.lm.plot2)
      adj.r2.plot2<- paste("Adj R2 = ", round(summary(sst.anom.lm.plot2)$adj.r.squared, 3), sep = "")
      
      # Fitted model formula
      my.formula.plot2<- paste("Mean.SST = ", signif(round(sst.anom.lm.plot2$coef[[1]], 3), 5), " + ", signif(round(sst.anom.lm.plot2$coef[[2]], 3), 5), "*Year", sep = "")
      base.ts.form<- base.ts +
        geom_smooth(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("2008-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2017-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), method = "lm", formula = y ~ x, col = "red", size = 0.75, se = FALSE) +
        geom_text(aes(x = as.Date("1987-06-15"), y = -2.8, label = my.formula.plot2), col = "red") +
        geom_text(aes(x = as.Date("1997-06-15"), y = -2.8, label = adj.r2.plot2), col = "red") 
      base.ts.form
      ggsave("~/Desktop/KM_sstanomaly_Baseand07to18.jpg", width = 8, height = 6, units = "in")
      dev.off()
      
      # Add 1982-1993
      sst.anom.lm.plot3<- lm(Mean.SST ~ Year.Model, data = subset(ts.df.yearlymu, Year >= 1982 & Year <= 1993))
      summary(sst.anom.lm.plot3)
      adj.r2.plot3<- paste("Adj R2 = ", round(summary(sst.anom.lm.plot3)$adj.r.squared, 3), sep = "")
      
      # Fitted model formula
      my.formula.plot3<- paste("Mean.SST = ", signif(round(sst.anom.lm.plot3$coef[[1]], 3), 5), " - ", signif(round(abs(sst.anom.lm.plot3$coef[[2]]), 3), 5), "*Year", sep = "")
      
      plot3<- base.ts.form +
        geom_smooth(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("1993-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), method = "lm", formula = y ~ x, col = "#7570b3", size = 0.75, se = FALSE) +
        geom_text(aes(x = as.Date("1987-06-15"), y = -4.15, label = my.formula.plot3), col = "#7570b3") +
        geom_text(aes(x = as.Date("1997-06-15"), y = -4.15, label = adj.r2.plot3), col = "#7570b3") 
      plot3
      ggsave("~/Desktop/KM_sstanomaly_Plot3.eps", width = 8, height = 6, units = "in")
      dev.off()
      
      # Add 1993-2004
      sst.anom.lm.plot4<- lm(Mean.SST ~ Year.Model, data = subset(ts.df.yearlymu, Year >= 1993 & Year <= 2004))
      summary(sst.anom.lm.plot4)
      adj.r2.plot4<- paste("Adj R2 = ", round(summary(sst.anom.lm.plot4)$adj.r.squared, 3), sep = "")
      
      # Fitted model formula
      my.formula.plot4<- paste("Mean.SST = ", signif(round(sst.anom.lm.plot4$coef[[1]], 3), 5), " + ", signif(round(sst.anom.lm.plot4$coef[[2]], 3), 5), "*Year", sep = "")
      
      plot4<- plot3 +
        geom_smooth(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1993-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2004-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), method = "lm", formula = y ~ x, col = "#1b9e77", size = 0.75, se = FALSE) +
        geom_text(aes(x = as.Date("1987-06-15"), y = -4.45, label = my.formula.plot4), col = "#1b9e77") +
        geom_text(aes(x = as.Date("1997-06-15"), y = -4.45, label = adj.r2.plot4), col = "#1b9e77") 
      plot4
      ggsave("~/Desktop/KM_sstanomaly_Plot4.eps", width = 8, height = 6, units = "in")
      dev.off() 
    } else {
      ylim.use<- c(-3.5,3.5)
      # Full trend line
      sst.anom.lm.full<- lm(Mean.SST ~ Year.Model, data = ts.df.yearlymu)
      summary(sst.anom.lm.full)
      adj.r2.full<- paste("Adj R2 = ", round(summary(sst.anom.lm.full)$adj.r.squared, 3), sep = "")
      
      # Fitted model formula
      my.formula.full<- paste("Mean.SST = ", signif(round(sst.anom.lm.full$coef[[1]], 3), 5), " + ", signif(round(sst.anom.lm.full$coef[[2]], 3), 5), "*Year", sep = "")
      base.ts<- ggplot(data = subset(ts.df.dailymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2016-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = smoothed)) + 
        #geom_line(col = "#d9d9d9", lwd = 0.15) +
        geom_point(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2016-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), size = 3, col = "black") +
        geom_line(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2016-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), col = "black", lwd = 0.25) +
        geom_smooth(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2016-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), method = "lm", formula = y ~ x, col = "#969696", size = 0.75, se = FALSE) +
        ylim(ylim.use) +
        ylab("SST Anomaly (1982-2011 baseline)") + 
        xlab("Year") +
        theme_bw() +
        theme(axis.text=element_text(size=14),
              axis.title=element_text(size=16, face="bold"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank()) +
        geom_text(aes(x = as.Date("1987-06-15"), y = -2.25, label = my.formula.full), col = "#969696") +
        geom_text(aes(x = as.Date("1997-06-15"), y = -2.25, label = adj.r2.full), col = "#969696") 
      
      plot(base.ts)
      ggsave("~/Desktop/KM_sstanomaly_Plot1.eps", width = 8, height = 6, units = "in")
      
      # 2004-2015 trend line
      sst.anom.lm.plot2<- lm(Mean.SST ~ Year.Model, data = subset(ts.df.yearlymu, Year >= 2004 & Year <= 2015))
      summary(sst.anom.lm.plot2)
      adj.r2.plot2<- paste("Adj R2 = ", round(summary(sst.anom.lm.plot2)$adj.r.squared, 3), sep = "")
      
      # Fitted model formula
      my.formula.plot2<- paste("Mean.SST = ", signif(round(sst.anom.lm.plot2$coef[[1]], 3), 5), " + ", signif(round(sst.anom.lm.plot2$coef[[2]], 3), 5), "*Year", sep = "")
      base.ts.form<- base.ts +
        geom_smooth(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("2004-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2015-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), method = "lm", formula = y ~ x, col = "#d95f02", size = 0.75, se = FALSE) +
        geom_text(aes(x = as.Date("1987-06-15"), y = -2.5, label = my.formula.plot2), col = "#d95f02") +
        geom_text(aes(x = as.Date("1997-06-15"), y = -2.5, label = adj.r2.plot2), col = "#d95f02") 
      base.ts.form
      ggsave("~/Desktop/KM_sstanomaly_Plot2.eps", width = 8, height = 6, units = "in")
      dev.off()
      
      # Add 1982-1993
      sst.anom.lm.plot3<- lm(Mean.SST ~ Year.Model, data = subset(ts.df.yearlymu, Year >= 1982 & Year <= 1993))
      summary(sst.anom.lm.plot3)
      adj.r2.plot3<- paste("Adj R2 = ", round(summary(sst.anom.lm.plot3)$adj.r.squared, 3), sep = "")
      
      # Fitted model formula
      my.formula.plot3<- paste("Mean.SST = ", signif(round(sst.anom.lm.plot3$coef[[1]], 3), 5), " - ", signif(round(abs(sst.anom.lm.plot3$coef[[2]]), 3), 5), "*Year", sep = "")
      
      plot3<- base.ts.form +
        geom_smooth(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("1993-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), method = "lm", formula = y ~ x, col = "#7570b3", size = 0.75, se = FALSE) +
        geom_text(aes(x = as.Date("1987-06-15"), y = -2.75, label = my.formula.plot3), col = "#7570b3") +
        geom_text(aes(x = as.Date("1997-06-15"), y = -2.75, label = adj.r2.plot3), col = "#7570b3") 
      plot3
      ggsave("~/Desktop/KM_sstanomaly_Plot3.eps", width = 8, height = 6, units = "in")
      dev.off()
      
      # Add 1993-2004
      sst.anom.lm.plot4<- lm(Mean.SST ~ Year.Model, data = subset(ts.df.yearlymu, Year >= 1993 & Year <= 2004))
      summary(sst.anom.lm.plot4)
      adj.r2.plot4<- paste("Adj R2 = ", round(summary(sst.anom.lm.plot4)$adj.r.squared, 3), sep = "")
      
      # Fitted model formula
      my.formula.plot4<- paste("Mean.SST = ", signif(round(sst.anom.lm.plot4$coef[[1]], 3), 5), " + ", signif(round(sst.anom.lm.plot4$coef[[2]], 3), 5), "*Year", sep = "")
      
      plot4<- plot3 +
        geom_smooth(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1993-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2004-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), method = "lm", formula = y ~ x, col = "#1b9e77", size = 0.75, se = FALSE) +
        geom_text(aes(x = as.Date("1987-06-15"), y = -3, label = my.formula.plot4), col = "#1b9e77") +
        geom_text(aes(x = as.Date("1997-06-15"), y = -3, label = adj.r2.plot4), col = "#1b9e77") 
      plot4
      ggsave("~/Desktop/KM_sstanomaly_Plot4.eps", width = 8, height = 6, units = "in")
      dev.off()
    }
    
    
    # Other stuff for KM
    # Yearly means
    write.csv(ts.df.yearlymu, file = "~/Desktop/SSTAnom_YearlyMeansDegF.csv")
    
    full.ts<- ggplot(data = subset(ts.df.dailymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2016-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = smoothed)) + 
      # geom_line(col = "gray", lwd = 0.15) +
      geom_point(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2016-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), col = "black") +
      geom_line(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2016-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), col = "black", lwd = 0.25) +
      geom_smooth(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2016-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), method = "lm", formula = y ~ x, col = "black", size = 0.75, se = FALSE) +
      #stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), label.x.npc = "left", label.y.npc = 0.9, formula = my.formula, parse = TRUE, size = 3, col = "black") +
      ylim(c(-1.95, 2.65)) +
      ylab("SST Anomaly (1982-2011 baseline)") + 
      xlab("Date") +
      theme_bw() +
      theme(axis.text=element_text(size=14),
            axis.title=element_text(size=16, face="bold")) 
    plot(full.ts)
    
    
    
    
    
    
    x<-seq(from = 1982, to = 2015, by = 1)
    lm(ts.df.yearlymu$Mean.SST[-1] ~ x)
    
    cold.plot<- full.ts +
      geom_smooth(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("1992-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), method = "lm", formula = y ~ x, color = "blue", se = FALSE, size = 1.25) +
      stat_poly_eq(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("1982-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("1992-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST, label = paste(..eq.label.., ..rr.label.., sep = "~~~")), label.x.npc = "left", label.y.npc = 0.01, formula = y ~ x, parse = TRUE, size = 3, color = "blue") +
      ylim(c(-1.95, 2.65)) 
    plot(cold.plot)
    
    warming.plot<- full.ts +
      geom_smooth(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("2004-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2014-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST), method = "lm", formula = y ~ x, color = "red", se = FALSE, size = 1.25) +
      stat_poly_eq(data = subset(ts.df.yearlymu, Plot.Date >= as.Date("2004-01-01", format = "%Y-%m-%d") & Plot.Date <= as.Date("2014-12-31", format = "%Y-%m-%d")), aes(x = Plot.Date, y = Mean.SST, label = paste(..eq.label.., ..rr.label.., sep = "~~~")), label.x.npc = "right", label.y.npc = 0.01, formula = y ~ x, parse = TRUE, size = 3, color = "red") +
      ylim(c(-1.95, 2.65)) 
    plot(warming.plot)
  }
  # End function
}


 